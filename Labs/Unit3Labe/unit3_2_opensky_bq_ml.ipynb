{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaxMatteucci/mgmt467-analytics-portfolio/blob/main/unit3_2_opensky_bq_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8f61cc6"
      },
      "source": [
        "## Unit 3 - Lab 2: Opensky to Big Query Table"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 1: Python packages and authentication"
      ],
      "metadata": {
        "id": "SukrH0tPeFZ2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8908b17f",
        "outputId": "18ff94f0-8dba-42e4-e921-f82bb0740ca8"
      },
      "source": [
        "R\"\"\"\"\"\n",
        "This cell installs required Python packages and authenticates the user to Google Cloud.\n",
        "\n",
        "Packages installed:\n",
        "- google-cloud-storage: For interacting with Google Cloud Storage.\n",
        "- google-cloud-bigquery: For interacting with Google Cloud BigQuery.\n",
        "- requests: A popular HTTP library.\n",
        "\n",
        "Authentication:\n",
        "The cell authenticates the user to Google Cloud, enabling access to Google Cloud Platform (GCP) services.\n",
        "R\"\"\"\"\"\n",
        "!pip install google-cloud-storage google-cloud-bigquery requests\n",
        "\n",
        "from google.colab import auth\n",
        "print(\"Authenticating to Google Cloud...\")\n",
        "auth.authenticate_user()\n",
        "print(\"Authentication successful.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFORMATION: Project 'database-project-467' has no 'environment' tag set. Use either 'Production', 'Development', 'Test', or 'Staging'. Add an 'environment' tag using `gcloud resource-manager tags bindings create`.\n",
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "178da864"
      },
      "source": [
        "## Cell 2: Configure  project-specific variables and set the `gcloud` project.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7ab0f07",
        "outputId": "e9b82a8d-a693-4c72-daa7-12b8c4bc475f"
      },
      "source": [
        "R\"\"\"\n",
        "This cell configures essential project-specific variables for Google Cloud operations.\n",
        "\n",
        "It defines:\n",
        "- PROJECT_ID: The Google Cloud project ID.\n",
        "- GCP_REGION: The Google Cloud region for services.\n",
        "- GCS_BUCKET_NAME: The name of the Google Cloud Storage bucket.\n",
        "- GCS_FOLDER_PATH: The folder path within the GCS bucket for data storage.\n",
        "- BQ_DATASET: The BigQuery dataset name.\n",
        "- BQ_TABLE: The BigQuery table name for flight data.\n",
        "- FLIGHT_RECORD_LIMIT: A pipeline setting to limit records from the API.\n",
        "\n",
        "Finally, it sets the gcloud project configuration to the specified PROJECT_ID.\n",
        "R\"\"\"\n",
        "\n",
        "# --- !! CONFIGURE YOUR VARIABLES !! ---\n",
        "\n",
        "PROJECT_ID = \"database-project-467\"\n",
        "GCP_REGION = \"us-central1\"\n",
        "\n",
        "# --- GCS Bucket (Source & Target) ---\n",
        "GCS_BUCKET_NAME = \"opensky-max-467\"\n",
        "GCS_FOLDER_PATH = \"opensky-data\"   # change if you want a different folder name\n",
        "\n",
        "# --- BigQuery Table (Target) ---\n",
        "BQ_DATASET = \"training_dataset\"\n",
        "BQ_TABLE = \"flight_data\"\n",
        "\n",
        "# --- Pipeline Settings ---\n",
        "FLIGHT_RECORD_LIMIT = 500\n",
        "\n",
        "# -------------------------------------\n",
        "\n",
        "# Set the project for all gcloud commands\n",
        "!gcloud config set project $PROJECT_ID\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFORMATION: Project 'database-project-467' has no 'environment' tag set. Use either 'Production', 'Development', 'Test', or 'Staging'. Add an 'environment' tag using `gcloud resource-manager tags bindings create`.\n",
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "859fc125"
      },
      "source": [
        "## Cell 3: Define the `OpenSkyApi` class and helper functions for data parsing and formatting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe4d60cb",
        "outputId": "11ef70d0-7b2a-4dc3-8959-07a8197f0b36"
      },
      "source": [
        "R\"\"\"\n",
        "This cell defines the `OpenSkyApi` class, along with `StateVector` and `OpenSkyStates` helper classes, for interacting with the OpenSky Network API.\n",
        "\n",
        "It includes utility functions to:\n",
        "- Fetch real-time flight data from the OpenSky API.\n",
        "- Handle API rate limiting.\n",
        "- Parse and convert raw API data into a structured format suitable for storage and analysis.\n",
        "\n",
        "Additionally, it defines helper functions (`_convertTimestamp`, `_convert`, `_convertRow`) for data type conversion and formatting flight records.\n",
        "R\"\"\"\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "import datetime\n",
        "import calendar\n",
        "import time\n",
        "import pprint\n",
        "import requests\n",
        "from collections import defaultdict\n",
        "from google.cloud import storage, bigquery\n",
        "\n",
        "# ==============================================================================\n",
        "# OpenSky API Library Code\n",
        "# ==============================================================================\n",
        "\n",
        "logger = logging.getLogger('opensky_api')\n",
        "logger.addHandler(logging.NullHandler())\n",
        "\n",
        "class StateVector(object):\n",
        "    keys = [\"icao24\", \"callsign\", \"origin_country\", \"time_position\",\n",
        "            \"last_contact\", \"longitude\", \"latitude\", \"baro_altitude\", \"on_ground\",\n",
        "            \"velocity\", \"heading\", \"vertical_rate\", \"sensors\",\n",
        "            \"geo_altitude\", \"squawk\", \"spi\", \"position_source\"]\n",
        "    def __init__(self, arr):\n",
        "        self.__dict__ = dict(zip(StateVector.keys, arr))\n",
        "\n",
        "class OpenSkyStates(object):\n",
        "    def __init__(self, j):\n",
        "        self.__dict__ = j\n",
        "        if self.states is not None:\n",
        "            self.states = [StateVector(a) for a in self.states]\n",
        "        else:\n",
        "            self.states = []\n",
        "\n",
        "class OpenSkyApi(object):\n",
        "    def __init__(self, username=None, password=None):\n",
        "        self._auth = (username, password) if username else ()\n",
        "        self._api_url = \"https://opensky-network.org/api\"\n",
        "        self._last_requests = defaultdict(lambda: 0)\n",
        "\n",
        "    def _get_json(self, url_post, callee, params=None):\n",
        "        r = requests.get(f\"{self._api_url}{url_post}\",\n",
        "                         auth=self._auth, params=params, timeout=60.00)\n",
        "        if r.status_code == 200:\n",
        "            self._last_requests[callee] = time.time()\n",
        "            return r.json()\n",
        "        logger.debug(f\"Response not OK. Status {r.status_code} - {r.reason}\")\n",
        "        return None\n",
        "\n",
        "    def _check_rate_limit(self, time_diff_noauth, time_diff_auth, func):\n",
        "        if len(self._auth) < 2:\n",
        "            return abs(time.time() - self._last_requests[func]) >= time_diff_noauth\n",
        "        return abs(time.time() - self._last_requests[func]) >= time_diff_auth\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_lat(lat):\n",
        "        if not -90 <= lat <= 90:\n",
        "            raise ValueError(f\"Invalid latitude {lat}!\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_lon(lon):\n",
        "        if not -180 <= lon <= 180:\n",
        "            raise ValueError(f\"Invalid longitude {lon}!\")\n",
        "\n",
        "    def get_states(self, time_secs=0, icao24=None, serials=None, bbox=()):\n",
        "        if not self._check_rate_limit(10, 5, self.get_states):\n",
        "            logger.debug(\"Blocking request due to rate limit\")\n",
        "            return None\n",
        "        t = calendar.timegm(time_secs.timetuple()) if isinstance(time_secs, datetime.datetime) else int(time_secs)\n",
        "        params = {\"time\": t, \"icao24\": icao24}\n",
        "        if len(bbox) == 4:\n",
        "            self._check_lat(bbox[0]); self._check_lat(bbox[1]); self._check_lon(bbox[2]); self._check_lon(bbox[3])\n",
        "            params.update({\"lamin\": bbox[0], \"lamax\": bbox[1], \"lomin\": bbox[2], \"lomax\": bbox[3]})\n",
        "        states_json = self._get_json(\"/states/all\", self.get_states, params=params)\n",
        "        return OpenSkyStates(states_json) if states_json else None\n",
        "\n",
        "# ==============================================================================\n",
        "# Data Parser Functions\n",
        "# ==============================================================================\n",
        "\n",
        "def _convertTimestamp(timestamp):\n",
        "    if timestamp is not None:\n",
        "        try:\n",
        "            return datetime.datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        except: pass\n",
        "    return None\n",
        "\n",
        "def _convert(data,dataType):\n",
        "    if data is not None:\n",
        "        if dataType==str: return data.strip()\n",
        "        try: return dataType(data)\n",
        "        except: return None\n",
        "    return None\n",
        "\n",
        "def _convertRow(flightState, queryTime):\n",
        "    row = {\n",
        "        'icao24': _convert(flightState.icao24,str),\n",
        "        'callsign': _convert(flightState.callsign,str),\n",
        "        'origin': _convert(flightState.origin_country,str),\n",
        "        'time':_convert( flightState.time_position,int),\n",
        "        'contact':_convert( flightState.last_contact,int),\n",
        "        'longitude':_convert( flightState.longitude,float),\n",
        "        'latitude':_convert( flightState.latitude,float),\n",
        "        'altitude':_convert( flightState.geo_altitude,float),\n",
        "        'on_ground':_convert( flightState.on_ground,bool),\n",
        "        'velocity':_convert( flightState.velocity,float),\n",
        "        'heading':_convert( flightState.heading,float),\n",
        "        'vertical_rate':_convert( flightState.vertical_rate,float),\n",
        "        'sensors':_convert( flightState.sensors,str),\n",
        "        'baro_altitude':_convert( flightState.baro_altitude,float),\n",
        "        'squawk':_convert( flightState.squawk,int),\n",
        "        'spi':_convert( flightState.spi,bool),\n",
        "        'position_source':_convert( flightState.position_source,int)\n",
        "    }\n",
        "    time_bq = _convertTimestamp(flightState.time_position)\n",
        "    if time_bq: row['time_bq'] = time_bq\n",
        "    contact_bq = _convertTimestamp(flightState.last_contact)\n",
        "    if contact_bq: row['contact_bq'] = contact_bq\n",
        "    query_time_bq = _convertTimestamp(queryTime)\n",
        "    if query_time_bq: row['query_time_bq'] = query_time_bq\n",
        "\n",
        "    # Return only non-null values, as BQ handles missing fields\n",
        "    return {k: v for k, v in row.items() if v is not None}\n",
        "\n",
        "print(\"✅ Helper functions and OpenSky API class defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Helper functions and OpenSky API class defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ffba020"
      },
      "source": [
        "## Cell 4: Define the `OpenSkyApi` class and helper functions, initialize GCP clients, define the BigQuery schema, and implement the data pipeline logic.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "323deb8f",
        "outputId": "d6198789-1cbf-4e4b-b6f3-44ca9512a1eb"
      },
      "source": [
        "R\"\"\"\n",
        "OPEN SKY INGESTION PIPELINE\n",
        "This cell defines:\n",
        "- OpenSky API classes\n",
        "- Clean + consistent row conversion\n",
        "- GCP clients (Storage + BigQuery)\n",
        "- CORRECT BigQuery schema\n",
        "- load_gcs_to_bigquery()\n",
        "- run_full_pipeline()\n",
        "\n",
        "Everything works end-to-end.\n",
        "R\"\"\"\n",
        "\n",
        "# ======================================================================\n",
        "# Imports\n",
        "# ======================================================================\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "import datetime\n",
        "import calendar\n",
        "import time\n",
        "import requests\n",
        "from collections import defaultdict\n",
        "from google.cloud import storage, bigquery\n",
        "\n",
        "# ======================================================================\n",
        "# Logger\n",
        "# ======================================================================\n",
        "logger = logging.getLogger(\"opensky_api\")\n",
        "logger.addHandler(logging.NullHandler())\n",
        "\n",
        "# ======================================================================\n",
        "# OpenSky Data Model\n",
        "# ======================================================================\n",
        "\n",
        "class StateVector:\n",
        "    keys = [\n",
        "        \"icao24\", \"callsign\", \"origin_country\", \"time_position\",\n",
        "        \"last_contact\", \"longitude\", \"latitude\", \"baro_altitude\",\n",
        "        \"on_ground\", \"velocity\", \"heading\", \"vertical_rate\", \"sensors\",\n",
        "        \"geo_altitude\", \"squawk\", \"spi\", \"position_source\"\n",
        "    ]\n",
        "\n",
        "    def __init__(self, arr):\n",
        "        # Zip the raw array into named fields\n",
        "        self.__dict__ = dict(zip(StateVector.keys, arr))\n",
        "\n",
        "\n",
        "class OpenSkyStates:\n",
        "    def __init__(self, j):\n",
        "        self.__dict__ = j\n",
        "        if self.states is not None:\n",
        "            self.states = [StateVector(a) for a in self.states]\n",
        "        else:\n",
        "            self.states = []\n",
        "\n",
        "\n",
        "class OpenSkyApi:\n",
        "    def __init__(self, username=None, password=None):\n",
        "        self._auth = (username, password) if username else ()\n",
        "        self._api_url = \"https://opensky-network.org/api\"\n",
        "        self._last_requests = defaultdict(lambda: 0)\n",
        "\n",
        "    def _get_json(self, path, callee, params=None):\n",
        "        r = requests.get(\n",
        "            f\"{self._api_url}{path}\",\n",
        "            auth=self._auth,\n",
        "            params=params,\n",
        "            timeout=60.0\n",
        "        )\n",
        "        if r.status_code == 200:\n",
        "            self._last_requests[callee] = time.time()\n",
        "            return r.json()\n",
        "        return None\n",
        "\n",
        "    def _check_rate_limit(self, unauth_delay, auth_delay, func):\n",
        "        elapsed = abs(time.time() - self._last_requests[func])\n",
        "        return elapsed >= (auth_delay if self._auth else unauth_delay)\n",
        "\n",
        "    def get_states(self, time_secs=0, icao24=None, serials=None, bbox=()):\n",
        "        if not self._check_rate_limit(10, 5, self.get_states):\n",
        "            return None\n",
        "\n",
        "        t = int(time_secs) if not isinstance(time_secs, datetime.datetime) else calendar.timegm(time_secs.timetuple())\n",
        "        params = {\"time\": t, \"icao24\": icao24}\n",
        "\n",
        "        if len(bbox) == 4:\n",
        "            params.update({\n",
        "                \"lamin\": bbox[0], \"lamax\": bbox[1],\n",
        "                \"lomin\": bbox[2], \"lomax\": bbox[3]\n",
        "            })\n",
        "\n",
        "        j = self._get_json(\"/states/all\", self.get_states, params=params)\n",
        "        return OpenSkyStates(j) if j else None\n",
        "\n",
        "# ======================================================================\n",
        "# Helpers\n",
        "# ======================================================================\n",
        "\n",
        "def _ts(ts):\n",
        "    if ts is None:\n",
        "        return None\n",
        "    try:\n",
        "        return datetime.datetime.fromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def _convert(value, dtype):\n",
        "    if value is None:\n",
        "        return None\n",
        "    try:\n",
        "        return dtype(value)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def _convertRow(state, query_time):\n",
        "    \"\"\"\n",
        "    Convert a StateVector into a clean dict.\n",
        "    These keys MATCH the BigQuery schema EXACTLY.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"icao24\": _convert(state.icao24, str),\n",
        "        \"callsign\": _convert(state.callsign, str),\n",
        "        \"origin_country\": _convert(state.origin_country, str),\n",
        "        \"time_position\": _convert(state.time_position, int),\n",
        "        \"last_contact\": _convert(state.last_contact, int),\n",
        "        \"longitude\": _convert(state.longitude, float),\n",
        "        \"latitude\": _convert(state.latitude, float),\n",
        "        \"baro_altitude\": _convert(state.baro_altitude, float),\n",
        "        \"on_ground\": _convert(state.on_ground, bool),\n",
        "        \"velocity\": _convert(state.velocity, float),\n",
        "        \"heading\": _convert(state.heading, float),\n",
        "        \"vertical_rate\": _convert(state.vertical_rate, float),\n",
        "        \"sensors\": _convert(state.sensors, str),\n",
        "        \"geo_altitude\": _convert(state.geo_altitude, float),\n",
        "        \"squawk\": _convert(state.squawk, str),   # STRING, not INT\n",
        "        \"spi\": _convert(state.spi, bool),\n",
        "        \"position_source\": _convert(state.position_source, int),\n",
        "        \"time_bq\": _ts(state.time_position),\n",
        "        \"contact_bq\": _ts(state.last_contact),\n",
        "        \"query_time_bq\": _ts(query_time)\n",
        "    }\n",
        "\n",
        "# ======================================================================\n",
        "# GCP Clients\n",
        "# ======================================================================\n",
        "\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# ======================================================================\n",
        "# CORRECT BIGQUERY SCHEMA\n",
        "# ======================================================================\n",
        "\n",
        "BQ_SCHEMA = [\n",
        "    bigquery.SchemaField(\"icao24\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"callsign\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"origin_country\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"time_position\", \"INT64\"),\n",
        "    bigquery.SchemaField(\"last_contact\", \"INT64\"),\n",
        "    bigquery.SchemaField(\"longitude\", \"FLOAT\"),\n",
        "    bigquery.SchemaField(\"latitude\", \"FLOAT\"),\n",
        "    bigquery.SchemaField(\"baro_altitude\", \"FLOAT\"),\n",
        "    bigquery.SchemaField(\"on_ground\", \"BOOL\"),\n",
        "    bigquery.SchemaField(\"velocity\", \"FLOAT\"),\n",
        "    bigquery.SchemaField(\"heading\", \"FLOAT\"),\n",
        "    bigquery.SchemaField(\"vertical_rate\", \"FLOAT\"),\n",
        "    bigquery.SchemaField(\"sensors\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"geo_altitude\", \"FLOAT\"),\n",
        "    bigquery.SchemaField(\"squawk\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"spi\", \"BOOL\"),\n",
        "    bigquery.SchemaField(\"position_source\", \"INT64\"),\n",
        "    bigquery.SchemaField(\"time_bq\", \"TIMESTAMP\"),\n",
        "    bigquery.SchemaField(\"contact_bq\", \"TIMESTAMP\"),\n",
        "    bigquery.SchemaField(\"query_time_bq\", \"TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "# ======================================================================\n",
        "# Load JSONL → BigQuery\n",
        "# ======================================================================\n",
        "\n",
        "def load_gcs_to_bigquery(gcs_uri, project_id, dataset, table, schema, bq_client_instance):\n",
        "    print(\"\\nStep: Loading data from GCS into BigQuery\")\n",
        "    print(\"  Source:\", gcs_uri)\n",
        "    print(f\"  Target: {dataset}.{table}\")\n",
        "\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
        "        schema=schema,\n",
        "        write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
        "        autodetect=False\n",
        "    )\n",
        "\n",
        "    load_job = bq_client_instance.load_table_from_uri(\n",
        "        gcs_uri,\n",
        "        f\"{project_id}.{dataset}.{table}\",\n",
        "        job_config=job_config\n",
        "    )\n",
        "\n",
        "    print(\"  Starting job:\", load_job.job_id)\n",
        "    load_job.result()\n",
        "    print(f\"  Loaded {load_job.output_rows} rows.\")\n",
        "    print(\"✅ Load complete.\")\n",
        "\n",
        "# ======================================================================\n",
        "# Full Pipeline\n",
        "# ======================================================================\n",
        "\n",
        "def run_full_pipeline():\n",
        "    print(f\"Step 1: Fetching up to {FLIGHT_RECORD_LIMIT} flights...\")\n",
        "    api = OpenSkyApi()\n",
        "    query_time = time.time()\n",
        "\n",
        "    result = api.get_states()\n",
        "    if not result or not result.states:\n",
        "        print(\"No data returned.\")\n",
        "        return None\n",
        "\n",
        "    rows = []\n",
        "    for state in result.states[:FLIGHT_RECORD_LIMIT]:\n",
        "        rows.append(_convertRow(state, query_time))\n",
        "\n",
        "    # Write JSONL\n",
        "    local_name = \"flight_data.jsonl\"\n",
        "    with open(local_name, \"w\") as f:\n",
        "        for r in rows:\n",
        "            f.write(json.dumps(r) + \"\\n\")\n",
        "\n",
        "    print(\"  Wrote JSONL:\", local_name)\n",
        "\n",
        "    # Upload to GCS\n",
        "    gcs_name = f\"{GCS_FOLDER_PATH}/opensky_batch_{int(query_time)}.jsonl\"\n",
        "    print(\"Step 2: Uploading to GCS:\", gcs_name)\n",
        "\n",
        "    bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "    blob = bucket.blob(gcs_name)\n",
        "    blob.upload_from_filename(local_name)\n",
        "\n",
        "    gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_name}\"\n",
        "    print(\"  Upload complete.\")\n",
        "    print(\"✅ API → GCS Finished.\")\n",
        "\n",
        "    return gcs_uri\n",
        "\n",
        "print(\"✅ All OpenSky ingestion functions defined.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All OpenSky ingestion functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50c8be80"
      },
      "source": [
        "## Cell 5: Execute the complete data pipeline.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "683da7fa",
        "outputId": "9a3087fd-57bb-4d07-8b7f-af6c5c8e9e2c"
      },
      "source": [
        "R\"\"\"\n",
        "This cell is intended to execute the full data pipeline, which typically involves:\n",
        "1. Fetching flight data from the OpenSky API.\n",
        "2. Uploading the fetched data to Google Cloud Storage (GCS).\n",
        "3. Loading the data from GCS into a BigQuery table.\n",
        "\n",
        "Note: The `run_full_pipeline()` function is assumed to be defined elsewhere in the notebook,\n",
        "encapsulating these steps.\n",
        "R\"\"\"\n",
        "run_full_pipeline()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Fetching up to 500 flights...\n",
            "  Wrote JSONL: flight_data.jsonl\n",
            "Step 2: Uploading to GCS: opensky-data/opensky_batch_1763669647.jsonl\n",
            "  Upload complete.\n",
            "✅ API → GCS Finished.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gs://opensky-max-467/opensky-data/opensky_batch_1763669647.jsonl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6ff6f7b"
      },
      "source": [
        "## Cell 6: Orchestrate the full data pipeline from API to GCS to BigQuery.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_pipeline_without_bq_load():\n",
        "    \"\"\"\n",
        "    Fetches data from the OpenSky API, flattens the 'states' array into\n",
        "    one JSON object per aircraft, writes JSONL, uploads to GCS,\n",
        "    and returns the GCS URI.\n",
        "    \"\"\"\n",
        "    import json\n",
        "    import requests\n",
        "    from datetime import datetime, timezone\n",
        "    from google.cloud import storage\n",
        "\n",
        "    url = \"https://opensky-network.org/api/states/all\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"❌ API request failed:\", response.status_code)\n",
        "        return None\n",
        "\n",
        "    data = response.json()\n",
        "\n",
        "    # The \"states\" list contains aircraft rows\n",
        "    rows = data.get(\"states\", [])\n",
        "    if not rows:\n",
        "        print(\"❌ No aircraft data returned from API\")\n",
        "        return None\n",
        "\n",
        "    # Each \"state\" row is a list with fixed positional fields\n",
        "    # Map them to column names\n",
        "    columns = [\n",
        "        \"icao24\", \"callsign\", \"origin_country\", \"time_position\",\n",
        "        \"last_contact\", \"longitude\", \"latitude\", \"baro_altitude\",\n",
        "        \"on_ground\", \"velocity\", \"heading\", \"vertical_rate\",\n",
        "        \"sensors\", \"geo_altitude\", \"squawk\", \"spi\",\n",
        "        \"position_source\"\n",
        "    ]\n",
        "\n",
        "    # Create timestamped file name\n",
        "    timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
        "    local_filename = f\"opensky_{timestamp}.jsonl\"\n",
        "\n",
        "    # Write JSONL properly (one aircraft per line)\n",
        "    with open(local_filename, \"w\") as f:\n",
        "        for row in rows:\n",
        "            # Some rows may have <17 fields. Pad with None.\n",
        "            row = row + [None] * (len(columns) - len(row))\n",
        "            item = dict(zip(columns, row))\n",
        "            f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "    # Upload to GCS\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "\n",
        "    blob_path = f\"{GCS_FOLDER_PATH}/{local_filename}\"\n",
        "    blob = bucket.blob(blob_path)\n",
        "    blob.upload_from_filename(local_filename)\n",
        "\n",
        "    gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{blob_path}\"\n",
        "    return gcs_uri\n"
      ],
      "metadata": {
        "id": "wGu6JuCL4QVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=\"database-project-467\")\n",
        "\n",
        "dataset_id = \"database-project-467.training_dataset\"\n",
        "dataset = bigquery.Dataset(dataset_id)\n",
        "dataset.location = \"us-central1\"\n",
        "\n",
        "client.create_dataset(dataset, exists_ok=True)\n",
        "\n",
        "print(\"Dataset created:\", dataset_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31HkRsLB4iNc",
        "outputId": "b87ab171-4716-4d56-980e-ec932bdf49f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created: database-project-467.training_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "426ba363",
        "outputId": "7c3d2b78-de52-47e0-d82d-1c1431dfd51b"
      },
      "source": [
        "\"\"\"\n",
        "This cell orchestrates the entire data pipeline, executing the following steps:\n",
        "1.  **Run API to GCS Pipeline**: It calls `run_full_pipeline_without_bq_load()` to fetch\n",
        "    flight data from the OpenSky API and upload it as a JSONL file to a Google Cloud Storage bucket.\n",
        "2.  **Load GCS to BigQuery**: If the GCS upload is successful, it then calls\n",
        "    `load_gcs_to_bigquery()` to load the data from the GCS URI into the specified BigQuery table.\n",
        "\n",
        "This ensures a complete data ingestion workflow from an external API to a data warehouse.\n",
        "R\"\"\"\n",
        "print(\"--- Running Full Data Pipeline (API -> GCS -> BigQuery) ---\")\n",
        "\n",
        "# 1. Execute API -> GCS pipeline\n",
        "gcs_uri_for_bq_load = run_full_pipeline_without_bq_load()\n",
        "\n",
        "if gcs_uri_for_bq_load:\n",
        "    # 2. Load data from GCS to BigQuery\n",
        "    load_gcs_to_bigquery(\n",
        "        gcs_uri_for_bq_load,\n",
        "        PROJECT_ID,\n",
        "        BQ_DATASET,\n",
        "        BQ_TABLE,\n",
        "        BQ_SCHEMA,\n",
        "        bq_client\n",
        "    )\n",
        "    print(\"✅ Pipeline Finished Successfully.\")\n",
        "else:\n",
        "    print(\"❌ Pipeline aborted: No data fetched or GCS upload failed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Full Data Pipeline (API -> GCS -> BigQuery) ---\n",
            "\n",
            "Step: Loading data from GCS into BigQuery\n",
            "  Source: gs://opensky-max-467/opensky-data/opensky_20251120_201417.jsonl\n",
            "  Target: training_dataset.flight_data\n",
            "  Starting job: fd9ec1d1-8722-481a-9d7c-8e912b6baeaf\n",
            "  Loaded 10764 rows.\n",
            "✅ Load complete.\n",
            "✅ Pipeline Finished Successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99a75f8d"
      },
      "source": [
        "## Cell 7: Create a BQML regression model to predict flight velocity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48c9295f",
        "outputId": "74d6d479-7feb-485e-fe89-d4bb84f64e8c"
      },
      "source": [
        "R\"\"\"\n",
        "BigQuery ML Regression Model\n",
        "Predict velocity using altitude + heading + vertical_rate\n",
        "\"\"\"\n",
        "print(\"--- Cell 6: Creating BQML Prediction (Regression) Model ---\")\n",
        "\n",
        "REGRESSION_MODEL_NAME = \"flight_velocity_predictor\"\n",
        "model_path = f\"{PROJECT_ID}.{BQ_DATASET}.{REGRESSION_MODEL_NAME}\"\n",
        "\n",
        "CREATE_PREDICTION_MODEL_QUERY = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{model_path}`\n",
        "OPTIONS(\n",
        "    model_type='LINEAR_REG',\n",
        "    input_label_cols=['velocity']\n",
        ") AS\n",
        "SELECT\n",
        "    velocity,\n",
        "    geo_altitude,\n",
        "    vertical_rate,\n",
        "    heading\n",
        "FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}`\n",
        "WHERE\n",
        "    velocity IS NOT NULL\n",
        "    AND geo_altitude IS NOT NULL\n",
        "    AND vertical_rate IS NOT NULL\n",
        "    AND heading IS NOT NULL\n",
        "    AND on_ground = false\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Creating regression model at: {model_path}\")\n",
        "print(\"This may take a few minutes...\")\n",
        "\n",
        "try:\n",
        "    job = bq_client.query(CREATE_PREDICTION_MODEL_QUERY)\n",
        "    job.result()\n",
        "    print(\"✅ Successfully created prediction model!\")\n",
        "\n",
        "    # Training info\n",
        "    stats = bq_client.query(\n",
        "        f\"SELECT * FROM ML.TRAINING_INFO(MODEL `{model_path}`)\"\n",
        "    ).result()\n",
        "    for row in stats:\n",
        "        print(f\"  > Iter {row['iteration']}: Loss = {row['loss']}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"❌ Error creating regression model:\", e)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Cell 6: Creating BQML Prediction (Regression) Model ---\n",
            "Creating regression model at: database-project-467.training_dataset.flight_velocity_predictor\n",
            "This may take a few minutes...\n",
            "✅ Successfully created prediction model!\n",
            "  > Iter 0: Loss = 1200.749951811304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09306c15"
      },
      "source": [
        "## Cell 8: Analyze `on_ground` label diversity in BigQuery\n",
        "\n",
        "Investigate the distribution of the `on_ground` column in the `flight_data` BigQuery table to understand why the classification model failed due to insufficient label diversity.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2371344",
        "outputId": "8f843e42-2439-47cf-d1f3-76a9797e0cf3"
      },
      "source": [
        "print(\"--- Analyzing 'on_ground' label diversity ---\")\n",
        "\n",
        "# Construct the SQL query to count distinct 'on_ground' values\n",
        "ANALYZE_ON_GROUND_QUERY = f\"\"\"\n",
        "SELECT\n",
        "    on_ground,\n",
        "    COUNT(*)\n",
        "FROM\n",
        "    `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}`\n",
        "GROUP BY\n",
        "    on_ground\n",
        "ORDER BY\n",
        "    on_ground DESC\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Executing query to analyze 'on_ground' distribution:\\n{ANALYZE_ON_GROUND_QUERY}\")\n",
        "\n",
        "# Execute the query\n",
        "try:\n",
        "    query_job = bq_client.query(ANALYZE_ON_GROUND_QUERY)\n",
        "    results = query_job.result()  # Wait for the query to complete\n",
        "\n",
        "    print(\"\\nResults for 'on_ground' distribution:\")\n",
        "    found_true = False\n",
        "    found_false = False\n",
        "    for row in results:\n",
        "        print(f\"  on_ground: {row['on_ground']}, Count: {row['f0_']}\")\n",
        "        if row['on_ground'] is True:\n",
        "            found_true = True\n",
        "        if row['on_ground'] is False:\n",
        "            found_false = True\n",
        "\n",
        "    if found_true and found_false:\n",
        "        print(\"✅ 'on_ground' column contains both TRUE and FALSE values. Label diversity is present.\")\n",
        "    elif found_true:\n",
        "        print(\"❌ 'on_ground' column contains only TRUE values. Insufficient label diversity for classification.\")\n",
        "    elif found_false:\n",
        "        print(\"❌ 'on_ground' column contains only FALSE values. Insufficient label diversity for classification.\")\n",
        "    else:\n",
        "        print(\"⚠️ No data found for 'on_ground' column.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error analyzing 'on_ground' diversity: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Analyzing 'on_ground' label diversity ---\n",
            "Executing query to analyze 'on_ground' distribution:\n",
            "\n",
            "SELECT\n",
            "    on_ground,\n",
            "    COUNT(*)\n",
            "FROM\n",
            "    `database-project-467.training_dataset.flight_data`\n",
            "GROUP BY\n",
            "    on_ground\n",
            "ORDER BY\n",
            "    on_ground DESC\n",
            "\n",
            "\n",
            "Results for 'on_ground' distribution:\n",
            "  on_ground: True, Count: 1041\n",
            "  on_ground: False, Count: 9723\n",
            "✅ 'on_ground' column contains both TRUE and FALSE values. Label diversity is present.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc27f768"
      },
      "source": [
        "## Cell 9: Create a BQML classification model to predict whether a flight is on the ground.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54196fb1",
        "outputId": "28566337-2c2e-47f0-f93e-a840bc4aa94c"
      },
      "source": [
        "R\"\"\"\n",
        "This cell creates a BigQuery ML (BQML) classification model.\n",
        "\n",
        "Purpose:\n",
        "- Classify whether a flight is on_ground\n",
        "- Features: geo_altitude, velocity\n",
        "- Handles NULLs safely\n",
        "R\"\"\"\n",
        "\n",
        "print(\"\\n--- Creating BQML Classification Model (with NULL handling) ---\")\n",
        "\n",
        "CLASSIFICATION_MODEL_NAME = \"flight_on_ground_classifier\"\n",
        "model_path = f\"{PROJECT_ID}.{BQ_DATASET}.{CLASSIFICATION_MODEL_NAME}\"\n",
        "\n",
        "CREATE_CLASSIFICATION_MODEL_QUERY = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{model_path}`\n",
        "OPTIONS(\n",
        "    model_type='LOGISTIC_REG',\n",
        "    input_label_cols=['on_ground'],\n",
        "    data_split_method='NO_SPLIT'\n",
        ") AS\n",
        "SELECT\n",
        "    CAST(on_ground AS INT64) AS on_ground,\n",
        "    COALESCE(geo_altitude, 0) AS geo_altitude,\n",
        "    COALESCE(velocity, 0) AS velocity\n",
        "FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}`\n",
        "WHERE\n",
        "    on_ground IS NOT NULL\n",
        "    AND (\n",
        "        (on_ground IS TRUE AND (geo_altitude IS NOT NULL OR velocity IS NOT NULL))\n",
        "        OR on_ground IS FALSE\n",
        "    )\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Creating classification model at: {model_path}\")\n",
        "print(\"This may take a few minutes...\")\n",
        "\n",
        "try:\n",
        "    job = bq_client.query(CREATE_CLASSIFICATION_MODEL_QUERY)\n",
        "    job.result()\n",
        "    print(f\"✅ Successfully created classification model: {CLASSIFICATION_MODEL_NAME}\")\n",
        "\n",
        "    # Training stats\n",
        "    stats = bq_client.query(\n",
        "        f\"SELECT * FROM ML.TRAINING_INFO(MODEL `{model_path}`)\"\n",
        "    ).result()\n",
        "    for row in stats:\n",
        "        print(f\"  > Iteration {row['iteration']}: Loss = {row['loss']}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"❌ Error creating classification model:\", e)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Creating BQML Classification Model (with NULL handling) ---\n",
            "Creating classification model at: database-project-467.training_dataset.flight_on_ground_classifier\n",
            "This may take a few minutes...\n",
            "✅ Successfully created classification model: flight_on_ground_classifier\n",
            "  > Iteration 19: Loss = 0.11589346069847577\n",
            "  > Iteration 18: Loss = 0.11756929146052185\n",
            "  > Iteration 17: Loss = 0.11972708069678267\n",
            "  > Iteration 16: Loss = 0.12354555834771706\n",
            "  > Iteration 15: Loss = 0.12779620520364982\n",
            "  > Iteration 14: Loss = 0.13220405194821588\n",
            "  > Iteration 13: Loss = 0.13470497100808018\n",
            "  > Iteration 12: Loss = 0.13866792675883474\n",
            "  > Iteration 11: Loss = 0.1425403912724544\n",
            "  > Iteration 10: Loss = 0.14632395673651677\n",
            "  > Iteration 9: Loss = 0.15087527553838775\n",
            "  > Iteration 8: Loss = 0.1560408161033985\n",
            "  > Iteration 7: Loss = 0.16300030753487\n",
            "  > Iteration 6: Loss = 0.17516714549806608\n",
            "  > Iteration 5: Loss = 0.21109012357476045\n",
            "  > Iteration 4: Loss = 0.2695982657323306\n",
            "  > Iteration 3: Loss = 0.3668911043916518\n",
            "  > Iteration 2: Loss = 0.4848944208543188\n",
            "  > Iteration 1: Loss = 0.5860514321890973\n",
            "  > Iteration 0: Loss = 0.6538206069497373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1d39797"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "**Why did the BQML classification model initially fail, and how was the issue resolved?**\n",
        "The BQML classification model initially failed because the `WHERE` clause in its creation query inadvertently filtered out all records where `on_ground` was `TRUE`. This happened because all 383 `on_ground=TRUE` records also had `NULL` values for either `altitude` or `velocity`, and the original `WHERE` clause explicitly excluded records with `NULL`s in these feature columns. The issue was resolved by modifying the model creation query to use `COALESCE(altitude, 0)` and `COALESCE(velocity, 0)` to handle these `NULL` values and adjusting the `WHERE` clause to ensure `on_ground=TRUE` records were included for training.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The initial attempt to create a BigQuery ML logistic regression model (`flight_on_ground_classifier`) for predicting `on_ground` status failed with an error stating \"Classification model requires at least 2 unique labels and the label column had only 1 unique label.\"\n",
        "*   Analysis of the `flight_data` BigQuery table confirmed that the `on_ground` column contained both `TRUE` (383 records) and `FALSE` (4117 records) values, indicating sufficient label diversity in the raw dataset.\n",
        "*   A diagnostic query revealed that the `WHERE` clause used in the model creation (`on_ground IS NOT NULL AND altitude IS NOT NULL AND velocity IS NOT NULL`) was the root cause, as it filtered out all records where `on_ground` was `TRUE`.\n",
        "*   Further investigation confirmed that all 383 records with `on_ground=TRUE` also had `NULL` values for either `altitude` or `velocity`, explaining why they were excluded by the `WHERE` clause.\n",
        "*   The `flight_velocity_predictor` BQML linear regression model was successfully created.\n",
        "*   After modifying the classification model query to use `COALESCE(altitude, 0)` and `COALESCE(velocity, 0)` for `NULL` handling and adjusting the `WHERE` clause, the `flight_on_ground_classifier` BigQuery ML logistic regression model was successfully created and trained.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   It is crucial to verify data conditions after applying filtering clauses, especially in `WHERE` statements for model training, as filtering can inadvertently remove necessary label diversity or critical data points.\n",
        "*   The `COALESCE` function proved effective in handling `NULL` values in feature columns, allowing for the inclusion of relevant data points that would otherwise be excluded, enabling successful model training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q&A, Data Findings, and Insights\n",
        "\n",
        "### Why did the BQML classification model initially fail?\n",
        "The classification model failed because the filtering in the WHERE clause removed every record where `on_ground` was TRUE. All on-ground rows had NULL values for either altitude or velocity, and the query required both fields to be non-NULL. This caused the training data to contain only `on_ground = FALSE` rows, which meant the label column had only one unique value. BigQuery ML requires at least two label values for classification, so the model creation failed.\n",
        "\n",
        "### How was the issue resolved?\n",
        "The issue was fixed by keeping on-ground rows in the dataset using:\n",
        "COALESCE(geo_altitude, 0)  \n",
        "COALESCE(velocity, 0)  \n",
        "This replaced NULL feature values with zeros and allowed those rows to remain. After adjusting the WHERE clause, the model trained successfully.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "- The first model attempt failed because the filtered label column contained only one unique value.\n",
        "- A full distribution check of the `on_ground` column showed both TRUE and FALSE values were present in the raw dataset.\n",
        "- All on-ground rows had NULL altitude or velocity, which caused them to be filtered out in the original query.\n",
        "- After switching to COALESCE and updating the filtering logic, the classification model (flight_on_ground_classifier) trained successfully.\n",
        "- The regression model (flight_velocity_predictor) also trained successfully.\n",
        "\n",
        "### Insights or Next Steps\n",
        "- Always check how filtering affects the dataset used for model training, since it can remove important label categories.\n",
        "- COALESCE is useful for handling missing values when dropping rows removes critical data.\n",
        "- With the classification model working, additional evaluation such as feature importance or prediction accuracy can now be explored.\n"
      ],
      "metadata": {
        "id": "cTgVyOeA6qaq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVC67f1v5zDT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
